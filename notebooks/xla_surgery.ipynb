{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d4yP7xZULvh"
   },
   "source": [
    "## XLA intermediate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TetbuBq29RY8",
    "outputId": "635661d9-3f0c-4a46-9f39-4145ebcd8252"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mini_net.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mini_net.py\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "NUM_SAMPLES = 1000\n",
    "DIM = 32\n",
    "CLASSES = 5\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    inputs = keras.Input(shape=(DIM,))\n",
    "    x = keras.layers.Dense(128, activation=\"relu\")(inputs)\n",
    "    x = keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "    outputs = keras.layers.Dense(CLASSES, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "def generate_dataset():\n",
    "    x = np.random.randn(NUM_SAMPLES, DIM)\n",
    "    y = np.random.randint(0, CLASSES, size=(NUM_SAMPLES,))\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    return dataset.batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "def train_model(args):\n",
    "    model = get_model()\n",
    "    if not args.jit_compile:\n",
    "        jit_compile = None\n",
    "    else:\n",
    "        jit_compile = True\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", jit_compile=jit_compile)\n",
    "\n",
    "    dataset = generate_dataset()\n",
    "    model.fit(dataset, epochs=5)\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--jit_compile\", action=\"store_true\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    train_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FDGI4F7yEs8t",
    "outputId": "56e9b72d-6f7d-4b7b-c474-ef6851cb34d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-12 15:00:29.418558: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-12 15:00:30.369614: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2023-03-12 15:00:30.369713: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2023-03-12 15:00:30.369732: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-12 15:00:33.350366: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "Epoch 1/5\n",
      "8/8 [==============================] - 5s 27ms/step - loss: 1.6557\n",
      "Epoch 2/5\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.5763\n",
      "Epoch 3/5\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.5391\n",
      "Epoch 4/5\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.5076\n",
      "Epoch 5/5\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4793\n"
     ]
    }
   ],
   "source": [
    "# From https://www.tensorflow.org/xla#reproducible_bug_reports\n",
    "!TF_DUMP_GRAPH_PREFIX=/tmp/generated \\\n",
    "  TF_XLA_FLAGS=\"--tf_xla_clustering_debug --tf_xla_auto_jit=2\" \\\n",
    "  XLA_FLAGS=\"--xla_dump_hlo_as_text --xla_dump_to=/tmp/generated\" \\\n",
    "    python mini_net.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m7yGFR92MYVU",
    "outputId": "f13d8146-daa7-4f3e-f14a-636251e3070d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-12 15:00:42.415271: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-12 15:00:43.875446: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2023-03-12 15:00:43.875543: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2023-03-12 15:00:43.875563: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-12 15:00:46.740244: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "Epoch 1/5\n",
      "8/8 [==============================] - 3s 132ms/step - loss: 1.6656\n",
      "Epoch 2/5\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.5870\n",
      "Epoch 3/5\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.5468\n",
      "Epoch 4/5\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.5142\n",
      "Epoch 5/5\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.4855\n"
     ]
    }
   ],
   "source": [
    "!TF_DUMP_GRAPH_PREFIX=/tmp/generated \\\n",
    "  TF_XLA_FLAGS=\"--tf_xla_clustering_debug --tf_xla_auto_jit=2\" \\\n",
    "  XLA_FLAGS=\"--xla_dump_hlo_as_text --xla_dump_to=/tmp/generated\" \\\n",
    "    python mini_net.py --jit_compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "amKt4jVIMn0a",
    "outputId": "37b90f1f-1b33-4b99-dd88-d206709d4290"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before_increase_dynamism_for_auto_jit_pass_10.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_11.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_12.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_13.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_14.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_15.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_16.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_17.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_18.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_19.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_1.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_20.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_21.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_22.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_23.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_24.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_25.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_26.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_27.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_28.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_29.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_2.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_30.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_31.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_32.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_33.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_34.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_35.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_36.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_37.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_38.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_39.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_3.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_40.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_41.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_42.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_4.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_5.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_6.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_7.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_8.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass_9.pbtxt\n",
      "before_increase_dynamism_for_auto_jit_pass.pbtxt\n",
      "before_mark_for_compilation_10.pbtxt\n",
      "before_mark_for_compilation_11.pbtxt\n",
      "before_mark_for_compilation_12.pbtxt\n",
      "before_mark_for_compilation_13.pbtxt\n",
      "before_mark_for_compilation_14.pbtxt\n",
      "before_mark_for_compilation_15.pbtxt\n",
      "before_mark_for_compilation_16.pbtxt\n",
      "before_mark_for_compilation_17.pbtxt\n",
      "before_mark_for_compilation_18.pbtxt\n",
      "before_mark_for_compilation_19.pbtxt\n",
      "before_mark_for_compilation_1.pbtxt\n",
      "before_mark_for_compilation_20.pbtxt\n",
      "before_mark_for_compilation_21.pbtxt\n",
      "before_mark_for_compilation_22.pbtxt\n",
      "before_mark_for_compilation_23.pbtxt\n",
      "before_mark_for_compilation_24.pbtxt\n",
      "before_mark_for_compilation_25.pbtxt\n",
      "before_mark_for_compilation_26.pbtxt\n",
      "before_mark_for_compilation_27.pbtxt\n",
      "before_mark_for_compilation_28.pbtxt\n",
      "before_mark_for_compilation_2.pbtxt\n",
      "before_mark_for_compilation_3.pbtxt\n",
      "before_mark_for_compilation_4.pbtxt\n",
      "before_mark_for_compilation_5.pbtxt\n",
      "before_mark_for_compilation_6.pbtxt\n",
      "before_mark_for_compilation_7.pbtxt\n",
      "before_mark_for_compilation_8.pbtxt\n",
      "before_mark_for_compilation_9.pbtxt\n",
      "before_mark_for_compilation.pbtxt\n",
      "lmhlo.module_0031.a_inference_run_step_633__.413.mlir\n",
      "lmhlo.module_0031.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.mlir\n",
      "lmhlo.module_0045.a_inference__update_step_xla_376__.31.mlir\n",
      "lmhlo.module_0045.a_inference__update_step_xla_401__.31.mlir\n",
      "lmhlo.module_0045.a_inference__update_step_xla_426__.31.mlir\n",
      "lmhlo.module_0045.a_inference__update_step_xla_451__.31.mlir\n",
      "lmhlo.module_0047.a_inference__update_step_xla_325__.31.mlir\n",
      "lmhlo.module_0047.a_inference__update_step_xla_376__.31.mlir\n",
      "lmhlo.module_0047.a_inference__update_step_xla_426__.31.mlir\n",
      "lmhlo.module_0047.a_inference__update_step_xla_451__.31.mlir\n",
      "lmhlo.module_0049.a_inference__update_step_xla_325__.31.mlir\n",
      "lmhlo.module_0049.a_inference__update_step_xla_376__.31.mlir\n",
      "lmhlo.module_0049.a_inference__update_step_xla_401__.31.mlir\n",
      "lmhlo.module_0049.a_inference__update_step_xla_451__.31.mlir\n",
      "lmhlo.module_0051.a_inference__update_step_xla_325__.31.mlir\n",
      "lmhlo.module_0051.a_inference__update_step_xla_351__.31.mlir\n",
      "lmhlo.module_0051.a_inference__update_step_xla_376__.31.mlir\n",
      "lmhlo.module_0051.a_inference__update_step_xla_401__.31.mlir\n",
      "lmhlo.module_0053.a_inference__update_step_xla_325__.31.mlir\n",
      "lmhlo.module_0053.a_inference__update_step_xla_351__.31.mlir\n",
      "lmhlo.module_0053.a_inference__update_step_xla_401__.31.mlir\n",
      "lmhlo.module_0053.a_inference__update_step_xla_426__.31.mlir\n",
      "lmhlo.module_0055.a_inference__update_step_xla_325__.31.mlir\n",
      "lmhlo.module_0055.a_inference__update_step_xla_351__.31.mlir\n",
      "lmhlo.module_0055.a_inference__update_step_xla_426__.31.mlir\n",
      "lmhlo.module_0057.cluster_0__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_4_.21.mlir\n",
      "lmhlo.module_0085.a_inference_run_step_633__.413.mlir\n",
      "lmhlo.module_0091.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.mlir\n",
      "mark_for_compilation_10.pbtxt\n",
      "mark_for_compilation_11.pbtxt\n",
      "mark_for_compilation_12.pbtxt\n",
      "mark_for_compilation_13.pbtxt\n",
      "mark_for_compilation_14.pbtxt\n",
      "mark_for_compilation_15.pbtxt\n",
      "mark_for_compilation_16.pbtxt\n",
      "mark_for_compilation_17.pbtxt\n",
      "mark_for_compilation_18.pbtxt\n",
      "mark_for_compilation_19.pbtxt\n",
      "mark_for_compilation_1.pbtxt\n",
      "mark_for_compilation_20.pbtxt\n",
      "mark_for_compilation_21.pbtxt\n",
      "mark_for_compilation_22.pbtxt\n",
      "mark_for_compilation_23.pbtxt\n",
      "mark_for_compilation_24.pbtxt\n",
      "mark_for_compilation_25.pbtxt\n",
      "mark_for_compilation_26.pbtxt\n",
      "mark_for_compilation_27.pbtxt\n",
      "mark_for_compilation_28.pbtxt\n",
      "mark_for_compilation_2.pbtxt\n",
      "mark_for_compilation_3.pbtxt\n",
      "mark_for_compilation_4.pbtxt\n",
      "mark_for_compilation_5.pbtxt\n",
      "mark_for_compilation_6.pbtxt\n",
      "mark_for_compilation_7.pbtxt\n",
      "mark_for_compilation_8.pbtxt\n",
      "mark_for_compilation_9.pbtxt\n",
      "mark_for_compilation_annotated_10.pbtxt\n",
      "mark_for_compilation_annotated_11.pbtxt\n",
      "mark_for_compilation_annotated_12.pbtxt\n",
      "mark_for_compilation_annotated_13.pbtxt\n",
      "mark_for_compilation_annotated_14.pbtxt\n",
      "mark_for_compilation_annotated_15.pbtxt\n",
      "mark_for_compilation_annotated_16.pbtxt\n",
      "mark_for_compilation_annotated_17.pbtxt\n",
      "mark_for_compilation_annotated_18.pbtxt\n",
      "mark_for_compilation_annotated_19.pbtxt\n",
      "mark_for_compilation_annotated_1.pbtxt\n",
      "mark_for_compilation_annotated_20.pbtxt\n",
      "mark_for_compilation_annotated_21.pbtxt\n",
      "mark_for_compilation_annotated_22.pbtxt\n",
      "mark_for_compilation_annotated_23.pbtxt\n",
      "mark_for_compilation_annotated_24.pbtxt\n",
      "mark_for_compilation_annotated_25.pbtxt\n",
      "mark_for_compilation_annotated_26.pbtxt\n",
      "mark_for_compilation_annotated_27.pbtxt\n",
      "mark_for_compilation_annotated_28.pbtxt\n",
      "mark_for_compilation_annotated_2.pbtxt\n",
      "mark_for_compilation_annotated_3.pbtxt\n",
      "mark_for_compilation_annotated_4.pbtxt\n",
      "mark_for_compilation_annotated_5.pbtxt\n",
      "mark_for_compilation_annotated_6.pbtxt\n",
      "mark_for_compilation_annotated_7.pbtxt\n",
      "mark_for_compilation_annotated_8.pbtxt\n",
      "mark_for_compilation_annotated_9.pbtxt\n",
      "mark_for_compilation_annotated.pbtxt\n",
      "mark_for_compilation.pbtxt\n",
      "module_0031.a_inference_run_step_633__.413.before_optimizations.txt\n",
      "module_0031.a_inference_run_step_633__.413.ir-no-opt.ll\n",
      "module_0031.a_inference_run_step_633__.413.ir-no-opt-noconst.ll\n",
      "module_0031.a_inference_run_step_633__.413.ir-with-opt.ll\n",
      "module_0031.a_inference_run_step_633__.413.ir-with-opt-noconst.ll\n",
      "module_0031.a_inference_run_step_633__.413.ptx\n",
      "module_0031.a_inference_run_step_633__.413.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0031.a_inference_run_step_633__.413.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0031.a_inference_run_step_633__.413.thunk_sequence\n",
      "module_0031.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.before_optimizations.txt\n",
      "module_0031.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.ir-no-opt.ll\n",
      "module_0031.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.ir-no-opt-noconst.ll\n",
      "module_0031.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.ir-with-opt.ll\n",
      "module_0031.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.ir-with-opt-noconst.ll\n",
      "module_0031.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.ptx\n",
      "module_0031.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0031.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0031.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.thunk_sequence\n",
      "module_0045.a_inference__update_step_xla_376__.31.before_optimizations.txt\n",
      "module_0045.a_inference__update_step_xla_376__.31.ir-no-opt.ll\n",
      "module_0045.a_inference__update_step_xla_376__.31.ir-no-opt-noconst.ll\n",
      "module_0045.a_inference__update_step_xla_376__.31.ir-with-opt.ll\n",
      "module_0045.a_inference__update_step_xla_376__.31.ir-with-opt-noconst.ll\n",
      "module_0045.a_inference__update_step_xla_376__.31.ptx\n",
      "module_0045.a_inference__update_step_xla_376__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0045.a_inference__update_step_xla_376__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0045.a_inference__update_step_xla_376__.31.thunk_sequence\n",
      "module_0045.a_inference__update_step_xla_401__.31.before_optimizations.txt\n",
      "module_0045.a_inference__update_step_xla_401__.31.ir-no-opt.ll\n",
      "module_0045.a_inference__update_step_xla_401__.31.ir-no-opt-noconst.ll\n",
      "module_0045.a_inference__update_step_xla_401__.31.ir-with-opt.ll\n",
      "module_0045.a_inference__update_step_xla_401__.31.ir-with-opt-noconst.ll\n",
      "module_0045.a_inference__update_step_xla_401__.31.ptx\n",
      "module_0045.a_inference__update_step_xla_401__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0045.a_inference__update_step_xla_401__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0045.a_inference__update_step_xla_401__.31.thunk_sequence\n",
      "module_0045.a_inference__update_step_xla_426__.31.before_optimizations.txt\n",
      "module_0045.a_inference__update_step_xla_426__.31.ir-no-opt.ll\n",
      "module_0045.a_inference__update_step_xla_426__.31.ir-no-opt-noconst.ll\n",
      "module_0045.a_inference__update_step_xla_426__.31.ir-with-opt.ll\n",
      "module_0045.a_inference__update_step_xla_426__.31.ir-with-opt-noconst.ll\n",
      "module_0045.a_inference__update_step_xla_426__.31.ptx\n",
      "module_0045.a_inference__update_step_xla_426__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0045.a_inference__update_step_xla_426__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0045.a_inference__update_step_xla_426__.31.thunk_sequence\n",
      "module_0045.a_inference__update_step_xla_451__.31.before_optimizations.txt\n",
      "module_0045.a_inference__update_step_xla_451__.31.ir-no-opt.ll\n",
      "module_0045.a_inference__update_step_xla_451__.31.ir-no-opt-noconst.ll\n",
      "module_0045.a_inference__update_step_xla_451__.31.ir-with-opt.ll\n",
      "module_0045.a_inference__update_step_xla_451__.31.ir-with-opt-noconst.ll\n",
      "module_0045.a_inference__update_step_xla_451__.31.ptx\n",
      "module_0045.a_inference__update_step_xla_451__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0045.a_inference__update_step_xla_451__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0045.a_inference__update_step_xla_451__.31.thunk_sequence\n",
      "module_0047.a_inference__update_step_xla_325__.31.before_optimizations.txt\n",
      "module_0047.a_inference__update_step_xla_325__.31.ir-no-opt.ll\n",
      "module_0047.a_inference__update_step_xla_325__.31.ir-no-opt-noconst.ll\n",
      "module_0047.a_inference__update_step_xla_325__.31.ir-with-opt.ll\n",
      "module_0047.a_inference__update_step_xla_325__.31.ir-with-opt-noconst.ll\n",
      "module_0047.a_inference__update_step_xla_325__.31.ptx\n",
      "module_0047.a_inference__update_step_xla_325__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0047.a_inference__update_step_xla_325__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0047.a_inference__update_step_xla_325__.31.thunk_sequence\n",
      "module_0047.a_inference__update_step_xla_376__.31.before_optimizations.txt\n",
      "module_0047.a_inference__update_step_xla_376__.31.ir-no-opt.ll\n",
      "module_0047.a_inference__update_step_xla_376__.31.ir-no-opt-noconst.ll\n",
      "module_0047.a_inference__update_step_xla_376__.31.ir-with-opt.ll\n",
      "module_0047.a_inference__update_step_xla_376__.31.ir-with-opt-noconst.ll\n",
      "module_0047.a_inference__update_step_xla_376__.31.ptx\n",
      "module_0047.a_inference__update_step_xla_376__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0047.a_inference__update_step_xla_376__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0047.a_inference__update_step_xla_376__.31.thunk_sequence\n",
      "module_0047.a_inference__update_step_xla_426__.31.before_optimizations.txt\n",
      "module_0047.a_inference__update_step_xla_426__.31.ir-no-opt.ll\n",
      "module_0047.a_inference__update_step_xla_426__.31.ir-no-opt-noconst.ll\n",
      "module_0047.a_inference__update_step_xla_426__.31.ir-with-opt.ll\n",
      "module_0047.a_inference__update_step_xla_426__.31.ir-with-opt-noconst.ll\n",
      "module_0047.a_inference__update_step_xla_426__.31.ptx\n",
      "module_0047.a_inference__update_step_xla_426__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0047.a_inference__update_step_xla_426__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0047.a_inference__update_step_xla_426__.31.thunk_sequence\n",
      "module_0047.a_inference__update_step_xla_451__.31.before_optimizations.txt\n",
      "module_0047.a_inference__update_step_xla_451__.31.ir-no-opt.ll\n",
      "module_0047.a_inference__update_step_xla_451__.31.ir-no-opt-noconst.ll\n",
      "module_0047.a_inference__update_step_xla_451__.31.ir-with-opt.ll\n",
      "module_0047.a_inference__update_step_xla_451__.31.ir-with-opt-noconst.ll\n",
      "module_0047.a_inference__update_step_xla_451__.31.ptx\n",
      "module_0047.a_inference__update_step_xla_451__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0047.a_inference__update_step_xla_451__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0047.a_inference__update_step_xla_451__.31.thunk_sequence\n",
      "module_0049.a_inference__update_step_xla_325__.31.before_optimizations.txt\n",
      "module_0049.a_inference__update_step_xla_325__.31.ir-no-opt.ll\n",
      "module_0049.a_inference__update_step_xla_325__.31.ir-no-opt-noconst.ll\n",
      "module_0049.a_inference__update_step_xla_325__.31.ir-with-opt.ll\n",
      "module_0049.a_inference__update_step_xla_325__.31.ir-with-opt-noconst.ll\n",
      "module_0049.a_inference__update_step_xla_325__.31.ptx\n",
      "module_0049.a_inference__update_step_xla_325__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0049.a_inference__update_step_xla_325__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0049.a_inference__update_step_xla_325__.31.thunk_sequence\n",
      "module_0049.a_inference__update_step_xla_376__.31.before_optimizations.txt\n",
      "module_0049.a_inference__update_step_xla_376__.31.ir-no-opt.ll\n",
      "module_0049.a_inference__update_step_xla_376__.31.ir-no-opt-noconst.ll\n",
      "module_0049.a_inference__update_step_xla_376__.31.ir-with-opt.ll\n",
      "module_0049.a_inference__update_step_xla_376__.31.ir-with-opt-noconst.ll\n",
      "module_0049.a_inference__update_step_xla_376__.31.ptx\n",
      "module_0049.a_inference__update_step_xla_376__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0049.a_inference__update_step_xla_376__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0049.a_inference__update_step_xla_376__.31.thunk_sequence\n",
      "module_0049.a_inference__update_step_xla_401__.31.before_optimizations.txt\n",
      "module_0049.a_inference__update_step_xla_401__.31.ir-no-opt.ll\n",
      "module_0049.a_inference__update_step_xla_401__.31.ir-no-opt-noconst.ll\n",
      "module_0049.a_inference__update_step_xla_401__.31.ir-with-opt.ll\n",
      "module_0049.a_inference__update_step_xla_401__.31.ir-with-opt-noconst.ll\n",
      "module_0049.a_inference__update_step_xla_401__.31.ptx\n",
      "module_0049.a_inference__update_step_xla_401__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0049.a_inference__update_step_xla_401__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0049.a_inference__update_step_xla_401__.31.thunk_sequence\n",
      "module_0049.a_inference__update_step_xla_451__.31.before_optimizations.txt\n",
      "module_0049.a_inference__update_step_xla_451__.31.ir-no-opt.ll\n",
      "module_0049.a_inference__update_step_xla_451__.31.ir-no-opt-noconst.ll\n",
      "module_0049.a_inference__update_step_xla_451__.31.ir-with-opt.ll\n",
      "module_0049.a_inference__update_step_xla_451__.31.ir-with-opt-noconst.ll\n",
      "module_0049.a_inference__update_step_xla_451__.31.ptx\n",
      "module_0049.a_inference__update_step_xla_451__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0049.a_inference__update_step_xla_451__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0049.a_inference__update_step_xla_451__.31.thunk_sequence\n",
      "module_0051.a_inference__update_step_xla_325__.31.before_optimizations.txt\n",
      "module_0051.a_inference__update_step_xla_325__.31.ir-no-opt.ll\n",
      "module_0051.a_inference__update_step_xla_325__.31.ir-no-opt-noconst.ll\n",
      "module_0051.a_inference__update_step_xla_325__.31.ir-with-opt.ll\n",
      "module_0051.a_inference__update_step_xla_325__.31.ir-with-opt-noconst.ll\n",
      "module_0051.a_inference__update_step_xla_325__.31.ptx\n",
      "module_0051.a_inference__update_step_xla_325__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0051.a_inference__update_step_xla_325__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0051.a_inference__update_step_xla_325__.31.thunk_sequence\n",
      "module_0051.a_inference__update_step_xla_351__.31.before_optimizations.txt\n",
      "module_0051.a_inference__update_step_xla_351__.31.ir-no-opt.ll\n",
      "module_0051.a_inference__update_step_xla_351__.31.ir-no-opt-noconst.ll\n",
      "module_0051.a_inference__update_step_xla_351__.31.ir-with-opt.ll\n",
      "module_0051.a_inference__update_step_xla_351__.31.ir-with-opt-noconst.ll\n",
      "module_0051.a_inference__update_step_xla_351__.31.ptx\n",
      "module_0051.a_inference__update_step_xla_351__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0051.a_inference__update_step_xla_351__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0051.a_inference__update_step_xla_351__.31.thunk_sequence\n",
      "module_0051.a_inference__update_step_xla_376__.31.before_optimizations.txt\n",
      "module_0051.a_inference__update_step_xla_376__.31.ir-no-opt.ll\n",
      "module_0051.a_inference__update_step_xla_376__.31.ir-no-opt-noconst.ll\n",
      "module_0051.a_inference__update_step_xla_376__.31.ir-with-opt.ll\n",
      "module_0051.a_inference__update_step_xla_376__.31.ir-with-opt-noconst.ll\n",
      "module_0051.a_inference__update_step_xla_376__.31.ptx\n",
      "module_0051.a_inference__update_step_xla_376__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0051.a_inference__update_step_xla_376__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0051.a_inference__update_step_xla_376__.31.thunk_sequence\n",
      "module_0051.a_inference__update_step_xla_401__.31.before_optimizations.txt\n",
      "module_0051.a_inference__update_step_xla_401__.31.ir-no-opt.ll\n",
      "module_0051.a_inference__update_step_xla_401__.31.ir-no-opt-noconst.ll\n",
      "module_0051.a_inference__update_step_xla_401__.31.ir-with-opt.ll\n",
      "module_0051.a_inference__update_step_xla_401__.31.ir-with-opt-noconst.ll\n",
      "module_0051.a_inference__update_step_xla_401__.31.ptx\n",
      "module_0051.a_inference__update_step_xla_401__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0051.a_inference__update_step_xla_401__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0051.a_inference__update_step_xla_401__.31.thunk_sequence\n",
      "module_0053.a_inference__update_step_xla_325__.31.before_optimizations.txt\n",
      "module_0053.a_inference__update_step_xla_325__.31.ir-no-opt.ll\n",
      "module_0053.a_inference__update_step_xla_325__.31.ir-no-opt-noconst.ll\n",
      "module_0053.a_inference__update_step_xla_325__.31.ir-with-opt.ll\n",
      "module_0053.a_inference__update_step_xla_325__.31.ir-with-opt-noconst.ll\n",
      "module_0053.a_inference__update_step_xla_325__.31.ptx\n",
      "module_0053.a_inference__update_step_xla_325__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0053.a_inference__update_step_xla_325__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0053.a_inference__update_step_xla_325__.31.thunk_sequence\n",
      "module_0053.a_inference__update_step_xla_351__.31.before_optimizations.txt\n",
      "module_0053.a_inference__update_step_xla_351__.31.ir-no-opt.ll\n",
      "module_0053.a_inference__update_step_xla_351__.31.ir-no-opt-noconst.ll\n",
      "module_0053.a_inference__update_step_xla_351__.31.ir-with-opt.ll\n",
      "module_0053.a_inference__update_step_xla_351__.31.ir-with-opt-noconst.ll\n",
      "module_0053.a_inference__update_step_xla_351__.31.ptx\n",
      "module_0053.a_inference__update_step_xla_351__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0053.a_inference__update_step_xla_351__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0053.a_inference__update_step_xla_351__.31.thunk_sequence\n",
      "module_0053.a_inference__update_step_xla_401__.31.before_optimizations.txt\n",
      "module_0053.a_inference__update_step_xla_401__.31.ir-no-opt.ll\n",
      "module_0053.a_inference__update_step_xla_401__.31.ir-no-opt-noconst.ll\n",
      "module_0053.a_inference__update_step_xla_401__.31.ir-with-opt.ll\n",
      "module_0053.a_inference__update_step_xla_401__.31.ir-with-opt-noconst.ll\n",
      "module_0053.a_inference__update_step_xla_401__.31.ptx\n",
      "module_0053.a_inference__update_step_xla_401__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0053.a_inference__update_step_xla_401__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0053.a_inference__update_step_xla_401__.31.thunk_sequence\n",
      "module_0053.a_inference__update_step_xla_426__.31.before_optimizations.txt\n",
      "module_0053.a_inference__update_step_xla_426__.31.ir-no-opt.ll\n",
      "module_0053.a_inference__update_step_xla_426__.31.ir-no-opt-noconst.ll\n",
      "module_0053.a_inference__update_step_xla_426__.31.ir-with-opt.ll\n",
      "module_0053.a_inference__update_step_xla_426__.31.ir-with-opt-noconst.ll\n",
      "module_0053.a_inference__update_step_xla_426__.31.ptx\n",
      "module_0053.a_inference__update_step_xla_426__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0053.a_inference__update_step_xla_426__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0053.a_inference__update_step_xla_426__.31.thunk_sequence\n",
      "module_0055.a_inference__update_step_xla_325__.31.before_optimizations.txt\n",
      "module_0055.a_inference__update_step_xla_325__.31.ir-no-opt.ll\n",
      "module_0055.a_inference__update_step_xla_325__.31.ir-no-opt-noconst.ll\n",
      "module_0055.a_inference__update_step_xla_325__.31.ir-with-opt.ll\n",
      "module_0055.a_inference__update_step_xla_325__.31.ir-with-opt-noconst.ll\n",
      "module_0055.a_inference__update_step_xla_325__.31.ptx\n",
      "module_0055.a_inference__update_step_xla_325__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0055.a_inference__update_step_xla_325__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0055.a_inference__update_step_xla_325__.31.thunk_sequence\n",
      "module_0055.a_inference__update_step_xla_351__.31.before_optimizations.txt\n",
      "module_0055.a_inference__update_step_xla_351__.31.ir-no-opt.ll\n",
      "module_0055.a_inference__update_step_xla_351__.31.ir-no-opt-noconst.ll\n",
      "module_0055.a_inference__update_step_xla_351__.31.ir-with-opt.ll\n",
      "module_0055.a_inference__update_step_xla_351__.31.ir-with-opt-noconst.ll\n",
      "module_0055.a_inference__update_step_xla_351__.31.ptx\n",
      "module_0055.a_inference__update_step_xla_351__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0055.a_inference__update_step_xla_351__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0055.a_inference__update_step_xla_351__.31.thunk_sequence\n",
      "module_0055.a_inference__update_step_xla_426__.31.before_optimizations.txt\n",
      "module_0055.a_inference__update_step_xla_426__.31.ir-no-opt.ll\n",
      "module_0055.a_inference__update_step_xla_426__.31.ir-no-opt-noconst.ll\n",
      "module_0055.a_inference__update_step_xla_426__.31.ir-with-opt.ll\n",
      "module_0055.a_inference__update_step_xla_426__.31.ir-with-opt-noconst.ll\n",
      "module_0055.a_inference__update_step_xla_426__.31.ptx\n",
      "module_0055.a_inference__update_step_xla_426__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0055.a_inference__update_step_xla_426__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0055.a_inference__update_step_xla_426__.31.thunk_sequence\n",
      "module_0057.cluster_0__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_4_.21.before_optimizations.txt\n",
      "module_0057.cluster_0__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_4_.21.ir-no-opt.ll\n",
      "module_0057.cluster_0__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_4_.21.ir-no-opt-noconst.ll\n",
      "module_0057.cluster_0__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_4_.21.ir-with-opt.ll\n",
      "module_0057.cluster_0__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_4_.21.ir-with-opt-noconst.ll\n",
      "module_0057.cluster_0__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_4_.21.ptx\n",
      "module_0057.cluster_0__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_4_.21.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0057.cluster_0__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_4_.21.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0057.cluster_0__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_4_.21.thunk_sequence\n",
      "module_0085.a_inference_run_step_633__.413.before_optimizations.txt\n",
      "module_0085.a_inference_run_step_633__.413.ir-no-opt.ll\n",
      "module_0085.a_inference_run_step_633__.413.ir-no-opt-noconst.ll\n",
      "module_0085.a_inference_run_step_633__.413.ir-with-opt.ll\n",
      "module_0085.a_inference_run_step_633__.413.ir-with-opt-noconst.ll\n",
      "module_0085.a_inference_run_step_633__.413.ptx\n",
      "module_0085.a_inference_run_step_633__.413.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0085.a_inference_run_step_633__.413.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0085.a_inference_run_step_633__.413.thunk_sequence\n",
      "module_0091.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.before_optimizations.txt\n",
      "module_0091.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.ir-no-opt.ll\n",
      "module_0091.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.ir-no-opt-noconst.ll\n",
      "module_0091.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.ir-with-opt.ll\n",
      "module_0091.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.ir-with-opt-noconst.ll\n",
      "module_0091.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.ptx\n",
      "module_0091.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "module_0091.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.sm_7.5_gpu_after_optimizations.txt\n",
      "module_0091.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.thunk_sequence\n"
     ]
    }
   ],
   "source": [
    "!ls /tmp/generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u7nG5nfoMtxI",
    "outputId": "95b56c0e-0867-4ee7-cd0e-d9f00cd92976"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/generated/module_0031.a_inference_run_step_633__.413.before_optimizations.txt\n",
      "/tmp/generated/module_0031.a_inference_run_step_633__.413.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0031.a_inference_run_step_633__.413.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0031.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.before_optimizations.txt\n",
      "/tmp/generated/module_0031.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0031.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0045.a_inference__update_step_xla_376__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0045.a_inference__update_step_xla_376__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0045.a_inference__update_step_xla_376__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0045.a_inference__update_step_xla_401__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0045.a_inference__update_step_xla_401__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0045.a_inference__update_step_xla_401__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0045.a_inference__update_step_xla_426__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0045.a_inference__update_step_xla_426__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0045.a_inference__update_step_xla_426__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0045.a_inference__update_step_xla_451__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0045.a_inference__update_step_xla_451__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0045.a_inference__update_step_xla_451__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0047.a_inference__update_step_xla_325__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0047.a_inference__update_step_xla_325__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0047.a_inference__update_step_xla_325__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0047.a_inference__update_step_xla_376__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0047.a_inference__update_step_xla_376__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0047.a_inference__update_step_xla_376__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0047.a_inference__update_step_xla_426__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0047.a_inference__update_step_xla_426__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0047.a_inference__update_step_xla_426__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0047.a_inference__update_step_xla_451__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0047.a_inference__update_step_xla_451__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0047.a_inference__update_step_xla_451__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0049.a_inference__update_step_xla_325__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0049.a_inference__update_step_xla_325__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0049.a_inference__update_step_xla_325__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0049.a_inference__update_step_xla_376__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0049.a_inference__update_step_xla_376__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0049.a_inference__update_step_xla_376__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0049.a_inference__update_step_xla_401__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0049.a_inference__update_step_xla_401__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0049.a_inference__update_step_xla_401__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0049.a_inference__update_step_xla_451__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0049.a_inference__update_step_xla_451__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0049.a_inference__update_step_xla_451__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0051.a_inference__update_step_xla_325__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0051.a_inference__update_step_xla_325__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0051.a_inference__update_step_xla_325__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0051.a_inference__update_step_xla_351__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0051.a_inference__update_step_xla_351__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0051.a_inference__update_step_xla_351__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0051.a_inference__update_step_xla_376__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0051.a_inference__update_step_xla_376__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0051.a_inference__update_step_xla_376__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0051.a_inference__update_step_xla_401__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0051.a_inference__update_step_xla_401__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0051.a_inference__update_step_xla_401__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0053.a_inference__update_step_xla_325__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0053.a_inference__update_step_xla_325__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0053.a_inference__update_step_xla_325__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0053.a_inference__update_step_xla_351__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0053.a_inference__update_step_xla_351__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0053.a_inference__update_step_xla_351__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0053.a_inference__update_step_xla_401__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0053.a_inference__update_step_xla_401__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0053.a_inference__update_step_xla_401__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0053.a_inference__update_step_xla_426__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0053.a_inference__update_step_xla_426__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0053.a_inference__update_step_xla_426__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0055.a_inference__update_step_xla_325__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0055.a_inference__update_step_xla_325__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0055.a_inference__update_step_xla_325__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0055.a_inference__update_step_xla_351__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0055.a_inference__update_step_xla_351__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0055.a_inference__update_step_xla_351__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0055.a_inference__update_step_xla_426__.31.before_optimizations.txt\n",
      "/tmp/generated/module_0055.a_inference__update_step_xla_426__.31.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0055.a_inference__update_step_xla_426__.31.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0057.cluster_0__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_4_.21.before_optimizations.txt\n",
      "/tmp/generated/module_0057.cluster_0__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_4_.21.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0057.cluster_0__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_4_.21.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0085.a_inference_run_step_633__.413.before_optimizations.txt\n",
      "/tmp/generated/module_0085.a_inference_run_step_633__.413.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0085.a_inference_run_step_633__.413.sm_7.5_gpu_after_optimizations.txt\n",
      "/tmp/generated/module_0091.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.before_optimizations.txt\n",
      "/tmp/generated/module_0091.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.sm_7.5_gpu_after_optimizations-buffer-assignment.txt\n",
      "/tmp/generated/module_0091.cluster_1__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_0__XlaNumResourceArgs_7_.188.sm_7.5_gpu_after_optimizations.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /tmp/generated/*.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOfzbUJFNNZv"
   },
   "source": [
    "The operation semantics are explained in [this guide](https://www.tensorflow.org/xla/operation_semantics). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69NTlK8aNXhy",
    "outputId": "aef321e3-68c6-482d-8fff-4a29d840f754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HloModule a_inference__update_step_xla_376__.31, input_output_alias={ {0}: (1, {}, may-alias), {1}: (2, {}, may-alias) }, alias_passthrough_params=true, entry_computation_layout={(f32[128,64]{1,0},f32[128,64]{1,0},f32[128,64]{1,0},f32[])->(f32[128,64]{1,0}, f32[128,64]{1,0})}\n",
      "\n",
      "fused_computation {\n",
      "  param_0 = f32[128,64]{1,0} parameter(0)\n",
      "  param_2.10 = f32[] parameter(2)\n",
      "  broadcast.1 = f32[128,64]{1,0} broadcast(param_2.10), dimensions={}, metadata={op_type=\"Mul\" op_name=\"mul_2\" source_file=\"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_experimental/rmsprop.py\" source_line=191}\n",
      "  param_1.9 = f32[128,64]{1,0} parameter(1)\n",
      "  multiply.1 = f32[128,64]{1,0} multiply(broadcast.1, param_1.9), metadata={op_type=\"Mul\" op_name=\"mul_2\" source_file=\"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_experimental/rmsprop.py\" source_line=191}\n",
      "  constant_2_clone_1 = f32[] constant(0.9), metadata={op_type=\"Mul\" op_name=\"mul\" source_file=\"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_experimental/rmsprop.py\" source_line=185}\n",
      "  broadcast.3.clone.1 = f32[128,64]{1,0} broadcast(constant_2_clone_1), dimensions={}, metadata={op_type=\"Mul\" op_name=\"mul\" source_file=\"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_experimental/rmsprop.py\" source_line=185}\n",
      "  param_3.6 = f32[128,64]{1,0} parameter(3)\n",
      "  multiply.4.clone.1 = f32[128,64]{1,0} multiply(broadcast.3.clone.1, param_3.6), metadata={op_type=\"Mul\" op_name=\"mul\" source_file=\"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_experimental/rmsprop.py\" source_line=185}\n",
      "  constant_1_clone_1 = f32[] constant(0.1), metadata={op_type=\"Mul\" op_name=\"mul_1\" source_file=\"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_experimental/rmsprop.py\" source_line=185}\n",
      "  broadcast.2.clone.1 = f32[128,64]{1,0} broadcast(constant_1_clone_1), dimensions={}, metadata={op_type=\"Mul\" op_name=\"mul_1\" source_file=\"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_experimental/rmsprop.py\" source_line=185}\n",
      "  multiply.3.clone.1 = f32[128,64]{1,0} multiply(param_1.9, param_1.9), metadata={op_type=\"Square\" op_name=\"Square\" source_file=\"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_experimental/rmsprop.py\" source_line=185}\n",
      "  multiply.2.clone.1 = f32[128,64]{1,0} multiply(broadcast.2.clone.1, multiply.3.clone.1), metadata={op_type=\"Mul\" op_name=\"mul_1\" source_file=\"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_experimental/rmsprop.py\" source_line=185}\n",
      "  add.2.clone.1 = f32[128,64]{1,0} add(multiply.4.clone.1, multiply.2.clone.1), metadata={op_type=\"AddV2\" op_name=\"add\" source_file=\"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_experimental/rmsprop.py\" source_line=185}\n",
      "  constant_0 = f32[] constant(1e-07), metadata={op_type=\"AddV2\" op_name=\"add_1\" source_file=\"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_experimental/rmsprop.py\" source_line=190}\n",
      "  broadcast.0 = f32[128,64]{1,0} broadcast(constant_0), dimensions={}, metadata={op_type=\"AddV2\" op_name=\"add_1\" source_file=\"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_experimental/rmsprop.py\" source_line=190}\n",
      "  add.1 = f32[128,64]{1,0} add(add.2.clone.1, broadcast.0), metadata={op_type=\"AddV2\" op_name=\"add_1\" source_file=\"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_experimental/rmsprop.py\" source_line=190}\n",
      "  rsqrt.0 = f32[128,64]{1,0} rsqrt(add.1), metadata={op_type=\"Rsqrt\" op_name=\"Rsqrt\"}\n",
      "  multiply.0 = f32[128,64]{1,0} multiply(multiply.1, rsqrt.0), metadata={op_type=\"Mul\" op_name=\"mul_3\" source_file=\"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_experimental/rmsprop.py\" source_line=191}\n",
      "  negate.0 = f32[128,64]{1,0} negate(multiply.0), metadata={op_type=\"Neg\" op_name=\"Neg\" source_file=\"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_experimental/rmsprop.py\" source_line=196}\n",
      "  add.0 = f32[128,64]{1,0} add(param_0, negate.0), metadata={op_type=\"AssignAddVariableOp\" op_name=\"AssignAddVariableOp\" source_file=\"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_experimental/rmsprop.py\" source_line=196}\n",
      "  ROOT tuple = (f32[128,64]{1,0}, f32[128,64]{1,0}) tuple(add.0, add.2.clone.1)\n",
      "}\n",
      "\n",
      "ENTRY a_inference__update_step_xla_376__.31 {\n",
      "  arg1.2 = f32[128,64]{1,0} parameter(1), parameter_replication={false}, metadata={op_name=\"XLA_Args\"}\n",
      "  arg0.1 = f32[128,64]{1,0} parameter(0), parameter_replication={false}, metadata={op_name=\"XLA_Args\"}\n",
      "  arg3.4 = f32[] parameter(3), parameter_replication={false}, metadata={op_name=\"XLA_Args\"}\n",
      "  arg2.3 = f32[128,64]{1,0} parameter(2), parameter_replication={false}, metadata={op_name=\"XLA_Args\"}\n",
      "  ROOT fusion = (f32[128,64]{1,0}, f32[128,64]{1,0}) fusion(arg1.2, arg0.1, arg3.4, arg2.3), kind=kLoop, calls=fused_computation, metadata={op_type=\"AssignAddVariableOp\" op_name=\"AssignAddVariableOp\" source_file=\"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_experimental/rmsprop.py\" source_line=196}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat /tmp/generated/module_0049.a_inference__update_step_xla_376__.31.sm_7.5_gpu_after_optimizations.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irxCVGrwUO47"
   },
   "source": [
    "## Interacting with `tf.function`\n",
    "\n",
    "Taken largely from [this guide](https://www.tensorflow.org/guide/function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "r3onPqqeQGHz"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jX1j9CT2QHsh"
   },
   "outputs": [],
   "source": [
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def dense_layer(x, w, b):\n",
    "    return add(tf.matmul(x, w), b)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def func_dense_layer(x, w, b):\n",
    "    return dense_layer(x, w, b)\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def jit_dense_layer(x, w, b):\n",
    "    return dense_layer(x, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CsJ7J1u-RvmN",
    "outputId": "fe13f324-58af-4889-fb2f-4d687b1ff216"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager dense: 2.2915861180008505\n",
      "Function dense: 0.1730724110002484\n",
      "JIT dense: 0.01554165000015928\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Eager dense:\",\n",
    "    timeit.timeit(\n",
    "        lambda: dense_layer(tf.ones([3, 2]), tf.ones([2, 2]), tf.ones([2])), number=10\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    \"Function dense:\",\n",
    "    timeit.timeit(\n",
    "        lambda: func_dense_layer(tf.ones([3, 2]), tf.ones([2, 2]), tf.ones([2])),\n",
    "        number=10,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Warm-up\n",
    "_ = jit_dense_layer(tf.ones([3, 2]), tf.ones([2, 2]), tf.ones([2]))\n",
    "print(\n",
    "    \"JIT dense:\",\n",
    "    timeit.timeit(\n",
    "        lambda: jit_dense_layer(tf.ones([3, 2]), tf.ones([2, 2]), tf.ones([2])),\n",
    "        number=10,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2JEROMZex1A"
   },
   "source": [
    "### Actual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wm35U45VdjWt",
    "outputId": "59740d75-a703-4eb7-fc8a-472dc475c728"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n",
      "Eager: 1.0998468459983997\n"
     ]
    }
   ],
   "source": [
    "mobilenet = tf.keras.applications.MobileNetV3Large()\n",
    "random_inputs = tf.random.normal((10, 224, 224, 3))\n",
    "\n",
    "# Warm-up\n",
    "_ = mobilenet.predict(random_inputs)\n",
    "print(\n",
    "    \"Eager:\",\n",
    "    timeit.timeit(lambda: mobilenet.predict(random_inputs, verbose=0), number=10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_HX6bWPGeKzl",
    "outputId": "8c362173-f37e-438f-a2c2-e86a2b32129d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n",
      "XLA: 0.6547937049999746\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "mobilenet = tf.keras.applications.MobileNetV3Large()\n",
    "mobilenet.compile(jit_compile=True)\n",
    "\n",
    "# Warm-up\n",
    "_ = mobilenet.predict(random_inputs)\n",
    "print(\"XLA:\", timeit.timeit(\n",
    "    lambda: mobilenet.predict(random_inputs, verbose=0),\n",
    "    number=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnvSbWi3gO72"
   },
   "source": [
    "Or, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a-3VxFo5f6XH",
    "outputId": "3bb63c4d-a7af-4ed8-8d2b-730be08989e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLA: 0.051761404998615035\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "mobilenet = tf.keras.applications.MobileNetV3Large()\n",
    "model_call_fn = tf.function(mobilenet, jit_compile=True)\n",
    "\n",
    "# Warm-up\n",
    "_ = model_call_fn(random_inputs, training=False)\n",
    "print(\n",
    "    \"XLA:\",\n",
    "    timeit.timeit(lambda: model_call_fn(random_inputs, training=False), number=10),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
